ungroup()
ggplot(data, aes(x = sentiment, y = n))+
geom_col(aes(fill = sentiment)) +
theme(legend.pos = "none")
df_words %>% filter(theme=="spirulina") %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup() %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
xlab("") + ylab("") +
coord_flip()
datatable(
df_bigram %>%
filter(theme=="spirulina") %>%
select(bigram, title) %>% distinct() %>%
count(bigram, sort = TRUE) %>%
filter(n > 20) %>% select(bigram, "Number of articles"=n)
)
wordCloud("steel production")
data = df_words %>% filter(theme=="steel production") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(negative + positive > 100) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(desc(score))
datatable(data)
data = df_words_summary %>% filter(theme == "phycocyanin") %>% top_n(200, n)
ggplot(data, aes(label = word, size = n, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 24) +
theme_minimal()
data_phy = df_words %>% filter(theme=="phycocyanin") %>% inner_join(get_sentiments("loughran"))
data_phy = data_phy %>%
count(sentiment, sort = TRUE) %>%
ungroup() %>% mutate(n = n / nrow(data_phy), label="phycocyanin")
data_all = df_words %>% inner_join(get_sentiments("loughran"))
data_all = data_all %>%
count(sentiment, sort = TRUE) %>%
ungroup() %>% mutate(n = n / nrow(data_all), label="all")
data = rbind(data_phy, data_all)
ggplot(data, aes(x = sentiment, y = n))+
geom_col(aes(fill = label), position="dodge")
data = df_words %>% filter(theme=="phycocyanin") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(negative + positive > 100) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(desc(score))
datatable(data)
df_bigram %>%
filter(theme=="phycocyanin") %>%
select(bigram, title) %>% distinct() %>%
count(bigram, sort = TRUE) %>%
top_n(10) %>%
mutate(bigram = reorder(bigram, n)) %>%
ggplot(aes(x = bigram, y = n)) +
geom_col(aes(fill=bigram)) +
theme(legend.pos = "none")+
coord_flip()
datatable(
df_bigram %>%
filter(theme=="phycocyanin") %>%
select(bigram, title) %>% distinct() %>%
count(bigram, sort = TRUE) %>%
filter(n > 3) %>% select(bigram, "Number of articles"=n)
)
data = df_words %>% inner_join(get_sentiments("bing")) %>%
count(theme, sentiment, sort = TRUE) %>%
ungroup()
ggplot(data, aes(x = theme, y = n))+
geom_col(aes(fill = sentiment))
data = df_words %>% inner_join(get_sentiments("afinn")) %>%
count(theme, value) %>%
ungroup()
ggplot(data, aes(x = theme, y = n))+
geom_col(aes(fill = value))
data = df_words %>% inner_join(get_sentiments("nrc")) %>%
count(theme, sentiment, sort = TRUE) %>%
ungroup()
ggplot(data, aes(x = theme, y = n))+
geom_col(aes(fill = sentiment))
data = df_words %>% inner_join(get_sentiments("loughran")) %>%
count(theme, sentiment, sort = TRUE) %>%
ungroup()
ggplot(data, aes(x = theme, y = n))+
geom_col(aes(fill = sentiment))
data = df_words %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
count(sentiment, theme) %>%
spread(sentiment, n, fill = 0)
data %>%
# positive score normalized by number of words
mutate(score = (positive - negative) / (positive + negative)) %>%
mutate(theme = reorder(theme, score)) %>%
ggplot(aes(theme, score, fill = score > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
ylab("") + xlab("Positivity score")
data = df_words_summary %>% filter(theme == "phycocyanin") %>% top_n(80, n)
ggplot(data, aes(label = word, size = n, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 24) +
theme_minimal()
knitr::opts_chunk$set(echo = FALSE)
#remotes::install_github("ianmoran11/mmtable2")
library(readxl)
library(tidyverse)
library(dplyr)
library(tidytext)
library(igraph)
library(ggwordcloud)
library(ggraph)
library(DT)
custom_stop = data.frame (
word  = c("1", "2", "3", "4", "5", "10", "it's", "."),
lexicon = "custom"
)
stop_words = rbind(stop_words, custom_stop)
#ogni file rappresenta un tema
list_of_files = list.files(path = "out",
recursive = TRUE,
pattern = "\\.csv$",
full.names = TRUE)
#tutti gli articoli caricati
df = list_of_files %>%
set_names() %>%
map_df(read_csv, .id = "file_name")
#parole del testo
df_words = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#parole del titolo
df_words_title = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#bigrammi del testo
df_bigram = df %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
filter(!is.na(bigram)) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ")
df_words_title_summary = df_words_title %>% group_by(word) %>% count(sort=TRUE) %>% ungroup()
df_words_summary = df_words %>% group_by(word, theme) %>% count(sort=TRUE) %>% ungroup()
df_words_tfidf = df_words %>%
count(theme, word) %>%
bind_tf_idf(word, theme, n) %>%
arrange(desc(tf_idf))
df_bigram_tfidf = df_bigram %>%
count(theme, bigram) %>%
bind_tf_idf(bigram, theme, n) %>%
arrange(desc(tf_idf))
df_themes = df %>% group_by(theme) %>% count() %>% ungroup() %>%
mutate(name=paste("theme:", theme), type="theme", color="yellow", label=paste(theme, " (", n ,")", sep = ""))
df_keywords = df %>% group_by(keywords) %>% count() %>% ungroup() %>%
mutate(name=paste("keyword:", keywords), type="keyword", color="orange", label=paste(keywords, " (", n ,")", sep = ""))
df_connections = df %>% group_by(theme, keywords) %>% count() %>% ungroup()
wordCloud = function(theme_name = NA){
data = rbind(
df_words_tfidf %>% filter(is.na(theme_name) | theme==theme_name) %>% top_n(30) %>% select(tf_idf, label=word),
df_bigram_tfidf %>% filter(is.na(theme_name) | theme==theme_name) %>% top_n(25) %>% select(tf_idf, label=bigram)
) %>% arrange(desc(tf_idf))
ggplot(data, aes(label = label, size = tf_idf, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 24) +
theme_minimal()
}
data = df_words_summary %>% filter(theme == "spirulina") %>% top_n(50, n)
ggplot(data, aes(label = word, size = n, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 24) +
theme_minimal()
vertices = rbind(
df_themes %>% select(name, type, color, label, n),
df_keywords %>% select(name, type, color, label, n)
)
relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)
g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 10 * log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=3) +
theme_graph() +
theme(legend.position = "none")
vertices = rbind(
df_themes %>% select(name, type, color, label, n),
df_keywords %>% select(name, type, color, label, n)
)
relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)
g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=3) +
theme_graph() +
theme(legend.position = "none")
vertices = rbind(
df_themes %>% select(name, type, color, label, n),
df_keywords %>% select(name, type, color, label, n)
)
relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)
g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 10 * log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=3) +
theme_graph() +
theme(legend.position = "none")
vertices = rbind(
df_themes %>% select(name, type, color, label, n),
df_keywords %>% select(name, type, color, label, n)
)
relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)
g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 10 * log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 100 * log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
data = df_words_title_summary %>% top_n(40, n)
data = df_words_title_summary %>% top_n(40, n)
ggplot(data, aes(label = word, size = n, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 24) +
theme_minimal()
data = df_words_title_summary %>% top_n(50, n)
ggplot(data, aes(label = word, size = n, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size = 20) +
theme_minimal()
knitr::opts_chunk$set(echo = FALSE)
#remotes::install_github("ianmoran11/mmtable2")
library(readxl)
library(tidyverse)
library(dplyr)
library(tidytext)
library(igraph)
library(ggwordcloud)
library(ggraph)
library(DT)
custom_stop = data.frame (
word  = c("1", "2", "3", "4", "5", "10", "it's", "."),
lexicon = "custom"
)
stop_words = rbind(stop_words, custom_stop)
#ogni file rappresenta un tema
list_of_files = list.files(path = "out",
recursive = TRUE,
pattern = "\\.csv$",
full.names = TRUE)
#tutti gli articoli caricati
df = list_of_files %>%
set_names() %>%
map_df(read_csv, .id = "file_name")
#parole del testo
df_words = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#parole del titolo
df_words_title = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#bigrammi del testo
df_bigram = df %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
filter(!is.na(bigram)) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ")
data = df_words %>% filter(theme=="sustainability") %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(positive + negative > 50) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(score)
datatable(data)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link2(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
knitr::opts_chunk$set(echo = FALSE)
#remotes::install_github("ianmoran11/mmtable2")
library(readxl)
library(tidyverse)
library(dplyr)
library(tidytext)
library(igraph)
library(ggwordcloud)
library(ggraph)
library(DT)
custom_stop = data.frame (
word  = c("1", "2", "3", "4", "5", "10", "it's", "."),
lexicon = "custom"
)
stop_words = rbind(stop_words, custom_stop)
#ogni file rappresenta un tema
list_of_files = list.files(path = "out",
recursive = TRUE,
pattern = "\\.csv$",
full.names = TRUE)
#tutti gli articoli caricati
df = list_of_files %>%
set_names() %>%
map_df(read_csv, .id = "file_name")
#parole del testo
df_words = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#parole del titolo
df_words_title = unnest_tokens(tbl = df, output = word, input = text)%>%
anti_join(stop_words)
#bigrammi del testo
df_bigram = df %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
filter(!is.na(bigram)) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
unite(bigram, word1, word2, sep = " ")
df_words_title_summary = df_words_title %>% group_by(word) %>% count(sort=TRUE) %>% ungroup()
df_words_summary = df_words %>% group_by(word, theme) %>% count(sort=TRUE) %>% ungroup()
df_words_tfidf = df_words %>%
count(theme, word) %>%
bind_tf_idf(word, theme, n) %>%
arrange(desc(tf_idf))
df_bigram_tfidf = df_bigram %>%
count(theme, bigram) %>%
bind_tf_idf(bigram, theme, n) %>%
arrange(desc(tf_idf))
df_themes = df %>% group_by(theme) %>% count() %>% ungroup() %>%
mutate(name=paste("theme:", theme), type="theme", color="yellow", label=paste(theme, " (", n ,")", sep = ""))
df_keywords = df %>% group_by(keywords) %>% count() %>% ungroup() %>%
mutate(name=paste("keyword:", keywords), type="keyword", color="orange", label=paste(keywords, " (", n ,")", sep = ""))
df_connections = df %>% group_by(theme, keywords) %>% count() %>% ungroup()
wordCloud = function(theme_name = NA){
data = rbind(
df_words_tfidf %>% filter(is.na(theme_name) | theme==theme_name) %>% top_n(30) %>% select(tf_idf, label=word),
df_bigram_tfidf %>% filter(is.na(theme_name) | theme==theme_name) %>% top_n(25) %>% select(tf_idf, label=bigram)
) %>% arrange(desc(tf_idf))
ggplot(data, aes(label = label, size = tf_idf, color = factor(sample.int(30, nrow(data), replace = TRUE)))) +
geom_text_wordcloud_area() +
scale_size_area(max_size= 20) +
theme_minimal()
}
data = df_themes %>% select(group=theme, value=n, label)
data = data %>%
arrange(desc(group)) %>%
mutate(prop = value / sum(data$value) *100) %>%
mutate(ypos = cumsum(prop)- 0.5*prop )
ggplot(data, aes(x="", y=prop, fill=group)) +
geom_bar(stat="identity", width=1, color="white", alpha=0.8) +
coord_polar("y", start=0) +
theme_void() +
theme(legend.position="none", plot.title = element_text(hjust = 0.5)) +
geom_text(aes(x=1.05, y = ypos, label = label), color = "white", size=4) +
scale_fill_brewer(palette="Set1")
ggplot(df_connections, aes(fill=keywords, y=n, x=theme)) +
geom_bar(position="dodge", stat="identity", color = "gray") +
geom_text(aes(y=n + 4, label = keywords), color = "black", size=2.2, position = position_dodge(0.9)) +
coord_flip() +
xlab("") + ylab("") +
theme(legend.position="none", plot.title = element_text(hjust = 0.5))
vertices = rbind(
df_themes %>% select(name, type, color, label, n),
df_keywords %>% select(name, type, color, label, n)
)
relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)
g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link2(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=3) +
theme_graph() +
theme(legend.position = "none")
ggraph(g, layout = 'graphopt') +
geom_node_point(aes(size = 1* log(n, 2), color=color, alpha=0.2)) +
geom_edge_link(aes(),
arrow = arrow(type = "closed", length = unit(1, 'mm'))) +
geom_node_text(aes(label = label), size=2.5) +
theme_graph() +
theme(legend.position = "none")
datatable(data) %>% formatStyle(columns = c(1, 2, 3, 4, 5), fontSize = '50%')
data = df_words %>% filter(theme=="phycocyanin") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(negative + positive > 100) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(desc(score))
data = df_words %>% filter(theme=="phycocyanin") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(negative + positive > 100) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(desc(score))
datatable(data) %>% formatStyle(columns = c(1, 2, 3, 4, 5), fontSize = '50%')
datatable(data) %>% formatStyle(columns = c(1), fontSize = '50%')
datatable(data) %>% formatStyle(columns = c(1), fontSize = '69%')
datatable(data) %>% formatStyle(columns = c(1), fontSize = '69%')
datatable(data) %>% formatStyle(fontSize = '69%')
datatable(data) %>% formatStyle(columns = c(1..10), fontSize = '69%')
datatable(data) %>% formatStyle(columns = c(1...10), fontSize = '69%')
data = df_words %>% filter(theme=="phycocyanin") %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(negative + positive > 100) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(desc(score))
datatable(data) %>% formatStyle(columns = c(1,2,3,4,5,6,7), fontSize = '69%')
data = df_words %>% filter(theme=="sustainability") %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(positive + negative > 50) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(score)
data = df_words %>% filter(theme=="sustainability") %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(positive + negative > 50) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(score
df_words %>% filter(theme=="sustainability") %>%
df_words %>% filter(theme=="sustainability") %>%
count(word) %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
group_by(sentiment) %>%
top_n(5, n) %>%
ungroup() %>%
mutate(word = reorder(word, n), fill=sentiment) %>%
ggplot(aes(word, n, fill=fill)) +
geom_col() +
coord_flip() +
facet_wrap(~ sentiment, scales = "free") +
theme(legend.pos = "none") + xlab("") + ylab("")
df_words %>% filter(theme=="sustainability") %>%
inner_join(get_sentiments("loughran"), by = "word") %>%
count(sentiment, title) %>%
spread(sentiment, n, fill = 0) %>%
filter(positive + negative > 50) %>%
mutate(score = (positive - negative) / (positive + negative)) %>%
drop_na(score) %>%
arrange(score)

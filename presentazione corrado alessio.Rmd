---
title: "A data-driven analysis for our start-up: INNOvALGAE"
author: "Corrado Alessio"
output: ioslides_presentation
fig_width: 8
fig_height: 5 
fig_align: "center"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readxl)
library(tidyverse)
library(dplyr)
library(tidytext)
library(igraph)
library(ggwordcloud)
library(ggraph)

custom_stop = data.frame (
  word  = c("1", "2", "3", "4", "5", "10" "it's", "."),
  lexicon = "custom"
)

stop_words = rbind(stop_words, custom_stop)


#ogni file rappresenta un tema
list_of_files = list.files(path = "out",
                            recursive = TRUE,
                            pattern = "\\.csv$",
                            full.names = TRUE)

#tutti gli articoli caricati
df = list_of_files %>%
    set_names() %>% 
    map_df(read_csv, .id = "file_name")

#parole del testo
df_words = unnest_tokens(tbl = df, output = word, input = text)%>%
  anti_join(stop_words)

#parole del titolo
df_words_title = unnest_tokens(tbl = df, output = word, input = text)%>%
  anti_join(stop_words)

#bigrammi del testo
df_bigram = df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  filter(!is.na(bigram)) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  unite(bigram, word1, word2, sep = " ")

df_words_title_summary = df_words_title %>% group_by(word) %>% count(sort=TRUE) %>% ungroup()

df_words_summary = df_words %>% group_by(word, theme) %>% count(sort=TRUE) %>% ungroup()

```


## Have you ever wandered about the consequences of using chemical colors? 

Two of the main industries where they are used are *cosmetics* and *textiles*.

The main danger from the use of these artificial colors are wastewaters: rich of dangerous substances like toxins and heavy metals. 

These waters end up in sea and rivers, and consequentely in the food we eat. 

When it comes to cosmetic products, safety concerns are rising: they can directly alter the skin, causing toxic effects on the long term. 


## Solution: the use of biologic molecules

Natural molecules can avoid us the use of chemical colorants. 

One of them, *Phycocyanin*, is the only blue dye found in nature. 

Phycocyanin can be extracted from a microalgae: Spirulina. 

Spirulina and Phycocyanin have several beneficial properties on our organism. They are also eco-friendly, free of waste and their production absorbs CO2 from the environment. 

This is the reason why we are launching our start-up: INNOvALGAE. 


## Goal of this research

The goal of this research is to find informations on the common sentiment about sustainability, climate change, chemical colorants and Spirulina/Phycocyanin.

These informations will help us to evaluate the current situation, find cues about customers' beliefs and guide our business decisions.


## Methodology

The steps followed by this study are the following: 

-  Collection of a large news dataset about the previous themes;
-  Analysis of the dataset to ensure complentess;
-  Analysis of the single themes to grab informations;
-  Analysis of the relations between themes and keywords to find relations.


## Data collection 

We have build a set of interesting keywords, grouped by themes. 

Then we have fed the keywords to a custom web crawler which:

- searches the keywords in Google News;
- downloads a processes the articles;
- saves them to csv files. 

The crawler was written in Python, while the analysis was performed using R. 


## Dataset

To start our analysis, we first calculate some metrics about the entire dataset. 

Main goals: 

- verification that it is complete 
- overview of the contained data
- overview of the links between data

```{r include=FALSE}


df_themes = df %>% group_by(theme) %>% count() %>% ungroup() %>%
  mutate(name=paste("theme:", theme), type="theme", color="yellow", label=paste(theme, " (", n ,")", sep = ""))

df_keywords = df %>% group_by(keywords) %>% count() %>% ungroup() %>%
  mutate(name=paste("keyword:", keywords), type="keyword", color="orange", label=paste(keywords, " (", n ,")", sep = "")) 

df_connections = df %>% group_by(theme, keywords) %>% count() %>% ungroup()


```



### Themes

```{r fig.height = 5, fig.width = 8, fig.align = "center"}

data = df_themes %>% select(group=theme, value=n, label)

# Compute the position of labels
data = data %>% 
  arrange(desc(group)) %>%
  mutate(prop = value / sum(data$value) *100) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop )

# Basic piechart
ggplot(data, aes(x="", y=prop, fill=group)) +
  geom_bar(stat="identity", width=1, color="white", alpha=0.8) +
  coord_polar("y", start=0) +
  theme_void() + 
  ggtitle("Number of articles for each theme") +
  theme(legend.position="none", plot.title = element_text(hjust = 0.5)) +
  geom_text(aes(x=1.05, y = ypos, label = label), color = "white", size=4) +
  scale_fill_brewer(palette="Set1")
```

## Keywords

```{r fig.height = 5, fig.width = 8, fig.align = "center"}
  

ggplot(df_connections, aes(fill=keywords, y=n, x=theme)) + 
    geom_bar(position="dodge", stat="identity", color = "gray") +
    geom_text(aes(y=n + 4, label = keywords), color = "black", size=2.2, position = position_dodge(0.9)) +
    coord_flip() +
    ggtitle("Number of articles for each keyword, grouped by theme") +
    xlab("") + ylab("") + 
    theme(legend.position="none", plot.title = element_text(hjust = 0.5)) 
```

## Searched Keywords

```{r fig.height = 5, fig.width = 8, fig.align = "center"}

vertices = rbind(
  df_themes %>% select(name, type, color, label, n), 
  df_keywords %>% select(name, type, color, label, n)
)

relations = df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label, n)

g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)

ggraph(g, layout = 'graphopt') + 
    geom_node_point(aes(size = log(n, 2), color=color, alpha=0.2)) +
    geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)), 
                   arrow = arrow(type = "closed", length = unit(1, 'mm'))) + 
    geom_node_text(aes(label = label), size=3) +
  theme_graph() +
  theme(legend.position = "none")


```



## Overall sentiment

```{r}

data = df_words %>% inner_join(get_sentiments("bing")) %>%
  count(sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = sentiment, y = n))+
  geom_col(aes(fill=sentiment)) +
  xlab("") + ylab("") + ggtitle("Overall sentiment")  + 
  theme(plot.title = element_text(hjust = 0.5)) 
  
```


## Most common words in the titles

```{r fig.height = 5, fig.width = 8, fig.align = "center"}

data = df_words_title_summary %>% top_n(100, n) 

ggplot(data, aes(label = word, size = n, color = factor(sample.int(10, nrow(data), replace = TRUE)))) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 24) +
  theme_minimal()

```




## Sustainability

Nowdays, sustainability is a priority.

Let's have an overview about the general sentiment about sustainability, and identify the major trends. 



```{r fig.height = 5, fig.width = 8, fig.align = "center"}

data = df_words_summary %>% filter(theme == "sustainability") %>% top_n(100, n)

ggplot(data, aes(label = word, size = n, color = factor(sample.int(10, nrow(data), replace = TRUE)))) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 24) +
  theme_minimal()

```





















```{r}

data = df_words %>% inner_join(get_sentiments("bing")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

data = df_words %>% inner_join(get_sentiments("afinn")) %>%
  count(theme, value) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = value))

data = df_words %>% inner_join(get_sentiments("nrc")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

data = df_words %>% inner_join(get_sentiments("loughran")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

```




```{r}

bigram_tf_idf = df_bigram %>%
  count(theme, bigram) %>%
  bind_tf_idf(bigram, theme, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf

```


```{r}

data = df_words %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  count(sentiment, theme) %>%
  spread(sentiment, n, fill = 0)

data %>%
  # positive score normalized by number of words
  mutate(score = (positive - negative) / (positive + negative)) %>%
  mutate(theme = reorder(theme, score)) %>%
  ggplot(aes(theme, score, fill = score > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip()

```

```{r}

df_words %>%
  count(word) %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  group_by(sentiment) %>%
  top_n(5, n) %>%
  ungroup() %>%
  # reorder treats its first argument as a categorical variable, and reorders its levels based on the values of a second variable
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ sentiment, scales = "free")

```


```{r}


df_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```


```{r}
```


---
title: "A data-driven presentation of our start-up: INNOvALGAE"
author: "Corrado Alessio"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(readxl)
library(tidyverse)
library(dplyr)
library(tidytext)
library(igraph)
library(ggwordcloud)

get_sentiments("bing")
get_sentiments("afinn")
get_sentiments("nrc")

#ogni file rappresenta un tema
list_of_files <- list.files(path = "out",
                            recursive = TRUE,
                            pattern = "\\.csv$",
                            full.names = TRUE)

#tutti gli articoli caricati
df <- list_of_files %>%
    set_names() %>% 
    map_df(read_csv, .id = "file_name")

#solo parole del testo
df_words = unnest_tokens(tbl = df, output = word, input = text)%>%
  anti_join(stop_words)

#solo parole del titolo
df_words_title = unnest_tokens(tbl = df, output = word, input = text)%>%
  anti_join(stop_words)

```


## Have you ever wandered about the consequences of using chemical colors? 

Two of the main industries where they are used are *cosmetics* and *textiles*.

The main danger from the use of these artificial colors are wastewaters: rich of dangerous substances like toxins and heavy metals. 

These waters end up in sea and rivers, and consequentely in the food we eat. 

When it comes to cosmetic products, safety concerns are rising: they can directly alter the skin, causing toxic effects on the long term. 


## Solution: the use of biologic molecules

Natural molecules can avoid us the use of chemical colorants. 

One of them, *Phycocyanin*, is the only blue dye found in nature. 

Phycocyanin can be extracted from a microalgae: Spirulina. 

Spirulina and Phycocyanin have several beneficial properties on our organism. They are also eco-friendly, free of waste and their production absorbs CO2 from the environment. 

This is the reason why we are launching our start-up: INNOvALGAE. 


## Goal of this research

The goal of this research is to find informations on the common sentiment about sustainability, climate change, chemical colorants and Spirulina/Phycocyanin.

These informations will help us to evaluate the current situation, find cues about customers' beliefs and guide our business decisions.


## Methodology

The steps followed by this study are the following: 

-  Collection of a large news dataset about the previous themes;
-  Analysis of the dataset to ensure complentess;
-  Analysis of the single themes to grab informations;
-  Analysis of the relations between themes and keywords to find relations.


## Data collection 

We have build a set of interesting keywords, grouped by themes. 

Then we have fed the keywords to a custom web crawler which:

- searches the keywords in Google News;
- downloads a processes the articles;
- saves them to csv files. 

The crawler was written in Python, while the analysis was performed using R. 


## Searched Keywords

```{r message=FALSE, warning=FALSE}

#Analysed themes and keywords

df_themes = df %>% group_by(theme) %>% count() %>% ungroup() %>%
  mutate(name=paste("theme:", theme), type="theme", color="yellow", label=paste(theme, " (", n ,")", sep = ""))

df_keywords = df %>% group_by(keywords) %>% count() %>% ungroup() %>%
  mutate(name=paste("keyword:", keywords), type="keyword", color="orange", label=paste(keywords, " (", n ,")", sep = "")) 

df_connections = df %>% group_by(theme, keywords) %>% count() %>% ungroup()


vertices <- rbind(
  df_themes %>% select(name, type, color, label), 
  df_keywords %>% select(name, type, color, label)
)

relations <- df_connections %>% mutate(from=paste("theme:", theme), to=paste("keyword:", keywords), label=n) %>% select(from, to, label)

g = graph_from_data_frame(relations, directed = TRUE, vertices = vertices)
plot(g)

```

## Number of articles

```{r}

data <- data.frame(
  group=LETTERS[1:5],
  value=c(13,7,9,21,2)
)

data = df_themes %>% select(group=theme, value=n, label)

# Compute the position of labels
data <- data %>% 
  arrange(desc(group)) %>%
  mutate(prop = value / sum(data$value) *100) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop )

# Basic piechart
ggplot(data, aes(x="", y=prop, fill=group)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  theme_void() + 
  theme(legend.position="none") +
  
  geom_text(aes(y = ypos, label = label), color = "white", size=4) +
  scale_fill_brewer(palette="Set1")

```

## Number of articles for each theme and keyword

```{r}

ggplot(df_connections, aes(x = theme, y = n))+
  geom_col(aes(fill = keywords))+
  coord_flip()+
  theme(legend.position = "none")+
  scale_fill_viridis_d()
  

```

## Most common words in the titles

```{r}

df_words_title_summary = df_words_title %>% filter(word != "1" & word != "2" & word != "itâ€™s") %>% group_by(word) %>% count() %>% ungroup() %>% top_n(30, n) %>% arrange(desc(n))

ggplot(df_words_title_summary, aes(label = word, size = n, color = factor(sample.int(10, nrow(df_words_title_summary), replace = TRUE)))) +
  geom_text_wordcloud_area() +
  scale_size_area(max_size = 24) +
  theme_minimal()

```



```{r}

data = df_words %>% inner_join(get_sentiments("bing")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

data = df_words %>% inner_join(get_sentiments("afinn")) %>%
  count(theme, value) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = value))

data = df_words %>% inner_join(get_sentiments("nrc")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

data = df_words %>% inner_join(get_sentiments("loughran")) %>%
  count(theme, sentiment, sort = TRUE) %>%
  ungroup()

ggplot(data, aes(x = theme, y = n))+
  geom_col(aes(fill = sentiment))

```




```{r}


df_bigram <- df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  filter(!is.na(bigram))

bigrams_separated <- df_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE) %>% top_n(10000) %>% unite(bigram, word1, word2, sep = " ")

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ") %>% semi_join(bigram_counts)

bigram_counts %>% top_n(100)



```

```{r}

bigram_tf_idf <- bigrams_united %>%
  count(theme, bigram) %>%
  bind_tf_idf(bigram, theme, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf

```


```{r}

library(tidygraph)
library(ggraph)

bigram_graph <- bigram_counts %>%
  filter(n > 20) %>% 
  as_tbl_graph()

bigram_graph

a <- grid::arrow(type = "closed", length = unit(.1, "inches"))

# plot the graph
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 1) +
  geom_node_text(aes(label = bigram), vjust = 1, hjust = 1) +
  theme_void()

```

```{r}

data <- df_words %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  count(sentiment, theme) %>%
  spread(sentiment, n, fill = 0)

data %>%
  # positive score normalized by number of words
  mutate(score = (positive - negative) / (positive + negative)) %>%
  mutate(theme = reorder(theme, score)) %>%
  ggplot(aes(theme, score, fill = score > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip()

```

```{r}

df_words %>%
  count(word) %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  group_by(sentiment) %>%
  top_n(5, n) %>%
  ungroup() %>%
  # reorder treats its first argument as a categorical variable, and reorders its levels based on the values of a second variable
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ sentiment, scales = "free")

```


```{r}


df_words %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```


```{r}
```

